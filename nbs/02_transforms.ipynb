{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#export\n",
    "from fastcore.all import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from transformers import PreTrainedTokenizer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "> Numericalize and Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformersNumericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TransformersNumericalize(Transform):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    def encodes(self, o):\n",
    "        ''' o: list of string token, returns: tensored list of int token '''\n",
    "        return TensorText(\n",
    "            self.tokenizer.build_inputs_with_special_tokens(\n",
    "                self.tokenizer.convert_tokens_to_ids(o)\n",
    "            )\n",
    "        )\n",
    "    def decodes(self, o):\n",
    "        return TitledStr(self.tokenizer.decode(list(o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tok_list = ['[CLS]', 'this', 'is', 'a', 'test', '[SEP]']\n",
    "num_list = TensorText([ 101, 2023, 2003, 1037, 3231,  102])\n",
    "transformersNumericalizer = TransformersNumericalize(tokenizer)\n",
    "\n",
    "test_eq(transformersNumericalizer.encodes(tok_list), num_list)\n",
    "test_eq(transformersNumericalizer.decodes(num_list), '[CLS] this is a test [SEP]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad2Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pad2Max(Transform):\n",
    "    ''' pad rank one tensor by pad_idx to max_len, if original len is larger than max_len, truncate it\n",
    "    '''\n",
    "    def __init__(self, max_len, pad_idx):\n",
    "        self.max_len = max_len\n",
    "        self.pad_idx = pad_idx\n",
    "    def encodes(self, o):\n",
    "        ori_len = len(o)\n",
    "        result = o\n",
    "        if ori_len > self.max_len:\n",
    "            result = o[:self.max_len]\n",
    "        elif ori_len < self.max_len:\n",
    "            result = nn.functional.pad(o, [0, self.max_len-ori_len], value=self.pad_idx)\n",
    "        assert len(result) == self.max_len, f'len(o): {len(o)}, max_len: {self.max_len}'\n",
    "        return result\n",
    "    def decodes(self, o):\n",
    "        return TensorText([v for v in o if v != self.pad_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad2max = Pad2Max(10, 1)\n",
    "\n",
    "num_list = torch.tensor([ 101, 2023, 2003, 1037, 3231,  102])\n",
    "padded_num_list = torch.tensor([ 101, 2023, 2003, 1037, 3231,  102,    1,    1,    1,    1])\n",
    "test_eq(pad2max(num_list), padded_num_list)\n",
    "\n",
    "pad2max = Pad2Max(3, 1)\n",
    "num_list = torch.tensor([ 101, 2023, 2003, 1037, 3231,  102])\n",
    "padded_num_list = torch.tensor([ 101, 2023, 2003])\n",
    "test_eq(pad2max(num_list), padded_num_list)\n",
    "\n",
    "pad2max = Pad2Max(6, 1)\n",
    "num_list = torch.tensor([ 101, 2023, 2003, 1037, 3231,  102])\n",
    "padded_num_list = torch.tensor([ 101, 2023, 2003, 1037, 3231,  102])\n",
    "test_eq(pad2max(num_list), padded_num_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_tokenizers.ipynb.\n",
      "Converted 02_transforms.ipynb.\n",
      "Converted 03_model_splits.ipynb.\n",
      "Converted 04_callbacks.ipynb.\n",
      "Converted 05_GeneratedLM.ipynb.\n",
      "Converted 99a_example_roberta_classification.ipynb.\n",
      "Converted 99b_example_gpt2_lm.ipynb.\n",
      "Converted 99c_example_GeneratedLM.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
