---

title: All functions

keywords: fastai
sidebar: home_sidebar


---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/00_general.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<p style="color: red;">
The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>
We recommend you <a href="https://www.tensorflow.org/guide/migrate" target="_blank">upgrade</a> now 
or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:
<a href="https://colab.research.google.com/notebooks/tensorflow_version.ipynb" target="_blank">more info</a>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<p style="color: red;">
The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>
We recommend you <a href="https://www.tensorflow.org/guide/migrate" target="_blank">upgrade</a> now 
or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:
<a href="https://colab.research.google.com/notebooks/tensorflow_version.ipynb" target="_blank">more info</a>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tokenizer">Tokenizer<a class="anchor-link" href="#Tokenizer">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TransformersTokenizer" class="doc_header"><code>class</code> <code>TransformersTokenizer</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L16" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TransformersTokenizer</code>(<strong><code>tokenizer</code></strong>:<code>PreTrainedTokenizer</code>)</p>
</blockquote>
<p>fastai want the tokenizer can handle list of string.
use in parallel_gen()</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>

<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;This is a test&#39;</span><span class="p">,</span> <span class="s1">&#39;Just test&#39;</span><span class="p">]</span>
<span class="n">transfomersTokenizer</span> <span class="o">=</span> <span class="n">TransformersTokenizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">tok_texts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">transfomersTokenizer</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span>

<span class="n">test_eq</span><span class="p">(</span><span class="n">tok_texts</span><span class="p">,</span> <span class="p">[[</span><span class="s1">&#39;this&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;just&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;This is a test&#39;</span><span class="p">,</span> <span class="s1">&#39;Just test&#39;</span><span class="p">]</span>
<span class="c1"># parallel_gen will return generator of (0, [&#39;this&#39;, &#39;is&#39;, &#39;a&#39;, &#39;test&#39;]), (1, [&#39;just&#39;, &#39;test&#39;])</span>
<span class="n">tok_texts</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">parallel_gen</span><span class="p">(</span><span class="n">TransformersTokenizer</span><span class="p">,</span> <span class="n">texts</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">))</span><span class="o">.</span><span class="n">itemgot</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">test_eq</span><span class="p">(</span><span class="n">tok_texts</span><span class="p">,</span> <span class="p">[[</span><span class="s1">&#39;this&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],[</span><span class="s1">&#39;just&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Transform">Transform<a class="anchor-link" href="#Transform">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TransformersNumericalize" class="doc_header"><code>class</code> <code>TransformersNumericalize</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L25" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TransformersNumericalize</code>(<strong><code>tokenizer</code></strong>:<code>PreTrainedTokenizer</code>) :: <code>Transform</code></p>
</blockquote>
<p>Delegates (<code>__call__</code>,<code>decode</code>,<code>setup</code>) to (<code>encodes</code>,<code>decodes</code>,<code>setups</code>) if <code>split_idx</code> matches</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tok_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;this&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]</span>
<span class="n">num_list</span> <span class="o">=</span> <span class="n">TensorText</span><span class="p">([</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span> <span class="mi">1037</span><span class="p">,</span> <span class="mi">3231</span><span class="p">,</span>  <span class="mi">102</span><span class="p">])</span>
<span class="n">transformersNumericalizer</span> <span class="o">=</span> <span class="n">TransformersNumericalize</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

<span class="n">test_eq</span><span class="p">(</span><span class="n">transformersNumericalizer</span><span class="o">.</span><span class="n">encodes</span><span class="p">(</span><span class="n">tok_list</span><span class="p">),</span> <span class="n">num_list</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">transformersNumericalizer</span><span class="o">.</span><span class="n">decodes</span><span class="p">(</span><span class="n">num_list</span><span class="p">),</span> <span class="s1">&#39;[CLS] this is a test [SEP]&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Pad2Max" class="doc_header"><code>class</code> <code>Pad2Max</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L39" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Pad2Max</code>(<strong><code>max_len</code></strong>, <strong><code>pad_idx</code></strong>) :: <code>Transform</code></p>
</blockquote>
<p>pad rank one tensor by pad_idx to max_len, if original len is larger than max_len, truncate it</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pad2max</span> <span class="o">=</span> <span class="n">Pad2Max</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">num_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span> <span class="mi">1037</span><span class="p">,</span> <span class="mi">3231</span><span class="p">,</span>  <span class="mi">102</span><span class="p">])</span>
<span class="n">padded_num_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span> <span class="mi">1037</span><span class="p">,</span> <span class="mi">3231</span><span class="p">,</span>  <span class="mi">102</span><span class="p">,</span>    <span class="mi">1</span><span class="p">,</span>    <span class="mi">1</span><span class="p">,</span>    <span class="mi">1</span><span class="p">,</span>    <span class="mi">1</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">pad2max</span><span class="p">(</span><span class="n">num_list</span><span class="p">),</span> <span class="n">padded_num_list</span><span class="p">)</span>

<span class="n">pad2max</span> <span class="o">=</span> <span class="n">Pad2Max</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">num_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span> <span class="mi">1037</span><span class="p">,</span> <span class="mi">3231</span><span class="p">,</span>  <span class="mi">102</span><span class="p">])</span>
<span class="n">padded_num_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">2003</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">pad2max</span><span class="p">(</span><span class="n">num_list</span><span class="p">),</span> <span class="n">padded_num_list</span><span class="p">)</span>

<span class="n">pad2max</span> <span class="o">=</span> <span class="n">Pad2Max</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">num_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span> <span class="mi">1037</span><span class="p">,</span> <span class="mi">3231</span><span class="p">,</span>  <span class="mi">102</span><span class="p">])</span>
<span class="n">padded_num_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2023</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span> <span class="mi">1037</span><span class="p">,</span> <span class="mi">3231</span><span class="p">,</span>  <span class="mi">102</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">pad2max</span><span class="p">(</span><span class="n">num_list</span><span class="p">),</span> <span class="n">padded_num_list</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Splitter">Splitter<a class="anchor-link" href="#Splitter">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bert_SeqClassification_split" class="doc_header"><code>bert_SeqClassification_split</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L60" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>bert_SeqClassification_split</code>(<strong><code>m</code></strong>:<code>Module</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="distilbert_SeqClassification_split" class="doc_header"><code>distilbert_SeqClassification_split</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L63" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>distilbert_SeqClassification_split</code>(<strong><code>m</code></strong>:<code>Module</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="albert_SeqClassification_split" class="doc_header"><code>albert_SeqClassification_split</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L66" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>albert_SeqClassification_split</code>(<strong><code>m</code></strong>:<code>Module</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="roberta_SeqClassification_split" class="doc_header"><code>roberta_SeqClassification_split</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L68" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>roberta_SeqClassification_split</code>(<strong><code>m</code></strong>:<code>Module</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpt2_lmhead_split" class="doc_header"><code>gpt2_lmhead_split</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L71" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>gpt2_lmhead_split</code>(<strong><code>m</code></strong>:<code>Module</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Callback">Callback<a class="anchor-link" href="#Callback">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">FakeLearner</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cb</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">cb</span><span class="o">.</span><span class="n">learn</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cb</span> <span class="o">=</span> <span class="n">cb</span>
    
    <span class="k">def</span> <span class="nf">run_cb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
        <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cb</span><span class="p">,</span> <span class="n">event_name</span><span class="p">)()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GPT2LMHeadCallback" class="doc_header"><code>class</code> <code>GPT2LMHeadCallback</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L76" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GPT2LMHeadCallback</code>() :: <code>Callback</code></p>
</blockquote>
<p>The output of AutoModelWithLMHead is (last_hidden_state, past)
What fastai want is last_hidden_state</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">FakeLearner</span><span class="p">(</span><span class="n">cb</span><span class="o">=</span><span class="n">GPT2LMHeadCallback</span><span class="p">(),</span> <span class="n">pred</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;last_hidden_state&#39;</span><span class="p">,</span> <span class="s1">&#39;past&#39;</span><span class="p">))</span>
<span class="n">learn</span><span class="o">.</span><span class="n">run_cb</span><span class="p">(</span><span class="s1">&#39;after_pred&#39;</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="s1">&#39;last_hidden_state&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertSeqClassificationCallback" class="doc_header"><code>class</code> <code>BertSeqClassificationCallback</code><a href="https://github.com/cwza/fastai_transformers_utils/tree/master/fastai_transformers_utils/general.py#L84" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertSeqClassificationCallback</code>(<strong><code>pad_id</code></strong>:<code>int</code>) :: <code>Callback</code></p>
</blockquote>
<p>It should be ok to use it in all Bert like model. eg: Roberta</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">FakeLearner</span><span class="p">(</span><span class="n">cb</span><span class="o">=</span><span class="n">BertSeqClassificationCallback</span><span class="p">(</span><span class="n">pad_id</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">xb</span><span class="o">=</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,))</span>
<span class="n">learn</span><span class="o">.</span><span class="n">run_cb</span><span class="p">(</span><span class="s1">&#39;begin_batch&#39;</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">xb</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Export">Export<a class="anchor-link" href="#Export">&#182;</a></h1>
</div>
</div>
</div>
</div>
 

